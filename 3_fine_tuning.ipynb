{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218ad961-ebc7-4168-99db-286b0b219b64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/anarci/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoethequant\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoethequant\u001b[0m (\u001b[33mantibody_generation\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/capstone_proteins_f2023/members/joseph/wandb/run-20231118_203335-1y1xfxrn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/antibody_generation/berkeley_antibody_generation/runs/1y1xfxrn' target=\"_blank\">simple_fine_tuned_progen2-small_prompted</a></strong> to <a href='https://wandb.ai/antibody_generation/berkeley_antibody_generation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/antibody_generation/berkeley_antibody_generation' target=\"_blank\">https://wandb.ai/antibody_generation/berkeley_antibody_generation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/antibody_generation/berkeley_antibody_generation/runs/1y1xfxrn' target=\"_blank\">https://wandb.ai/antibody_generation/berkeley_antibody_generation/runs/1y1xfxrn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/antibody_generation/berkeley_antibody_generation/runs/1y1xfxrn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ef70e2c1290>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install torch\n",
    "# pip install tokenizers\n",
    "# pip install transformers\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tokenizers import Tokenizer\n",
    "from models.progen.modeling_progen import ProGenForCausalLM\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from itertools import combinations\n",
    "from seq import ab_number as abn\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "### configure fine-tuning\n",
    "n_splits = 3\n",
    "epochs = 10\n",
    "batch_size = 20\n",
    "learning_rate = 1e-5\n",
    "foundation_model_name = 'simple_fine_tuned_progen2-small' #progen2-small, progen2-medium, progen2-large, progen2-xlarge,  simple_fine_tuned_progen2-small\n",
    "\n",
    "fine_tuning_strategy = None #None, simple_fine_tuned, frozen_layers_tuned, or etc\n",
    "prompting_strategy = 'prompted' #zero_shot or prompted\n",
    "\n",
    "if fine_tuning_strategy is None:\n",
    "    model_name = f'{foundation_model_name}'\n",
    "else:\n",
    "    model_name = f'{fine_tuning_strategy}_{foundation_model_name}'\n",
    "    \n",
    "experiment_name =f'{model_name}_{prompting_strategy}'\n",
    "run_description = f'Running {prompting_strategy} across {model_name}'\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"berkeley_antibody_generation\",\n",
    "    entity='antibody_generation',\n",
    "    name=experiment_name,\n",
    "    notes=run_description,\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": epochs,\n",
    "    \"foundational_model\": foundation_model_name,\n",
    "    \"model_name\": model_name,\n",
    "    \"run_description\": run_description,\n",
    "    \"fine_tuning_strategy\": fine_tuning_strategy\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d772c68-f3db-4604-8f84-fba6f3509d73",
   "metadata": {},
   "source": [
    "# Fine Tuning Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ca87c3-33f5-4828-92ed-269ebbbfa700",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tuning_strategy == 'simple_fine_tuned':\n",
    "    # Define a Dataset for loading protein sequences\n",
    "    class ProteinDataset(Dataset):\n",
    "        def __init__(self, sequences, tokenizer, begin_token_id, end_token_id):\n",
    "            self.tokenized_sequences = [tokenizer.encode(sequence, add_special_tokens=False) for sequence in sequences]\n",
    "            for i, encoding in enumerate(self.tokenized_sequences):\n",
    "                modified_ids = [begin_token_id] + encoding.ids + [end_token_id]\n",
    "                self.tokenized_sequences[i] = modified_ids\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.tokenized_sequences)\n",
    "    \n",
    "        def __getitem__(self, idx):\n",
    "            return self.tokenized_sequences[idx]\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        # Find the max length of sequences in the batch\n",
    "        max_length = max([len(sequence) for sequence in batch])\n",
    "        \n",
    "        # Pad each sequence to the max length and stack them\n",
    "        padded_input_ids = torch.stack([torch.tensor(sequence + [0]*(max_length - len(sequence))) for sequence in batch])\n",
    "        \n",
    "        return {\"input_ids\": padded_input_ids, \"labels\": padded_input_ids.clone()}\n",
    "    \n",
    "    \n",
    "    def main(epochs, batch_size, learning_rate, foundation_model_name):\n",
    "        \n",
    "        # Load the tokenizer\n",
    "        tokenizer = Tokenizer.from_file('tokenizer.json')\n",
    "\n",
    "\n",
    "        # load Model\n",
    "        model_path = f'./model_checkpoints/{foundation_model_name}'\n",
    "        \n",
    "        #initial load of single GPU, will handle multiple GPUs a few lines down.\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Load the pre-trained model\n",
    "        model = ProGenForCausalLM.from_pretrained(model_path).to(device)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "        # Check for multiple GPUs\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "            model = nn.DataParallel(model)\n",
    "        \n",
    "        sequences = []\n",
    "        # Open and read the file\n",
    "        with open(\"sabdab_joint_sequences_uniprot.txt\", \"r\") as file:\n",
    "            [sequences.append(line.strip()) for line in file]\n",
    "\n",
    "        # Create the KFold object\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Splitting the data for train, and test.\n",
    "        train_sequences, test_sequences = train_test_split(sequences, test_size=0.1, random_state=42)  # 70% train, 10% temp\n",
    "        \n",
    "        # Initialize test DataLoader for test set. Train and validation are handled in the training loop.\n",
    "        test_dataset = ProteinDataset(test_sequences, tokenizer, begin_token_id=1, end_token_id=2)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "        for fold, (train_ids, val_ids) in enumerate(kf.split(sequences)):\n",
    "            print(f\"FOLD {fold}\")\n",
    "            print(\"--------------------------------\")\n",
    "\n",
    "            # Splitting the data into the current fold\n",
    "            train_sequences = [sequences[index] for index in train_ids]\n",
    "            val_sequences = [sequences[index] for index in val_ids]\n",
    "\n",
    "            # Initialize DataLoaders for the current fold\n",
    "            train_dataset = ProteinDataset(train_sequences, tokenizer, begin_token_id=1, end_token_id=2)\n",
    "            val_dataset = ProteinDataset(val_sequences, tokenizer, begin_token_id=1, end_token_id=2)\n",
    "    \n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "            # Fine-tuning Loop\n",
    "            model.train()\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0.0\n",
    "                for batch in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    inputs = batch[\"input_ids\"].to(device)\n",
    "                    labels = batch[\"labels\"].to(device)\n",
    "                    outputs = model(inputs, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "        \n",
    "                    #ig using multiple GPUs, This ensures that the loss is always a scalar, irrespective of the number of GPUs.\n",
    "                    if loss.dim() > 0:\n",
    "                        loss = loss.sum()\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "        \n",
    "                avg_loss = total_loss / len(train_loader)\n",
    "                \n",
    "                # Evaluate on validation set\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for batch in val_loader:\n",
    "                        inputs = batch[\"input_ids\"].to(device)\n",
    "                        labels = batch[\"labels\"].to(device)\n",
    "                        outputs = model(inputs, labels=labels)\n",
    "                        loss = outputs.loss\n",
    "                        if loss.dim() > 0:\n",
    "                            loss = loss.sum()\n",
    "                        val_loss += loss.item()\n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "                \n",
    "                wandb.log({\"avg_train_loss\": avg_loss, \"avg_val_loss\": avg_val_loss})\n",
    "                \n",
    "                print(f\"Epoch: {epoch+1}/{epochs}, Training Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "            # Save the fine-tuned model\n",
    "            if isinstance(model, nn.DataParallel):\n",
    "                model.module.save_pretrained(f'model_checkpoints/{model_name}')\n",
    "            else:\n",
    "                model.save_pretrained(f'model_checkpoints/{model_name}')\n",
    "        \n",
    "\n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs = batch[\"input_ids\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                outputs = model(inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                if loss.dim() > 0:\n",
    "                    loss = loss.sum()\n",
    "                test_loss += loss.item()\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        wandb.log({\"test_loss\": avg_test_loss})\n",
    "        print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        main(epochs, batch_size, learning_rate, foundation_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebaceb6-ac44-4fc2-8097-ca121c434833",
   "metadata": {},
   "source": [
    "# Final Sampling Results and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a3dfe5-c8f8-42fd-bc01-04d0238182bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to add ANARCI to Path\n",
    "os.environ['PATH'] = '/root/miniconda3/envs/anarci/bin:' + os.environ['PATH']\n",
    "\n",
    "def run_anarci(sequence):\n",
    "    # Run ANARCI as a subprocess\n",
    "\n",
    "    result = subprocess.run(['ANARCI', '--sequence', sequence, '--scheme', 'aho'], capture_output=True, text=True)\n",
    "\n",
    "    sequence_results = result.stdout.split('\\n')\n",
    "\n",
    "    species = None\n",
    "    e_value = None\n",
    "    score = None\n",
    "    heavy_chain = np.array([])\n",
    "    light_chain = np.array([])\n",
    "\n",
    "    try: #push this into try as we do not want to stop the program if ANARCI fails. If it fails, it will return an empty arrays and thus not be included in the anarci results and data files.\n",
    "        if len(sequence_results) > 4:\n",
    "\n",
    "            blank, species, chain_type, e_value, score, seqstart_index, seqend_index, blank_2 = sequence_results[5].split('|')\n",
    "\n",
    "            h_seq = []\n",
    "            l_seq = []\n",
    "            for row in sequence_results[7:]:\n",
    "                row = [x for x in row.split(' ') if x != '']\n",
    "                if (len(row) == 3) and (row[0] == 'H'):       \n",
    "                    h_seq.append(row[2])\n",
    "                elif (len(row) == 3) and (row[0] == 'L'):\n",
    "                    l_seq.append(row[2])\n",
    "\n",
    "            heavy_chain = np.array(h_seq)\n",
    "            light_chain = np.array(l_seq)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return species, e_value, score, heavy_chain, light_chain\n",
    "\n",
    "\n",
    "def predict_sequence(model, tokenizer, sequence, device='cuda:0', number_of_sequences=1 ):\n",
    "    # Tokenize the sequence\n",
    "    tokenized_sequence = tokenizer.encode(sequence)\n",
    "    \n",
    "    # Convert to PyTorch tensor and add batch dimension\n",
    "    input_tensor = torch.tensor([tokenized_sequence.ids]).to(device)\n",
    "    \n",
    "    # Pass the tensor through the model\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_tensor, max_length=1024, pad_token_id=tokenizer.encode('<|pad|>').ids[0], do_sample=True, top_p=0.9, temperature=0.8, num_return_sequences=number_of_sequences)\n",
    "\n",
    "        as_lists = lambda batch: [batch[i, ...].detach().cpu().numpy().tolist() for i in range(batch.shape[0])]\n",
    "        sequences = tokenizer.decode_batch(as_lists(output))\n",
    "\n",
    "        if len(sequences) > 0:\n",
    "            sequences = [x.replace('2', '') for x in sequences] #replace stop token with empty string\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        sequence_with_heavy_and_light_chains = []\n",
    "\n",
    "        #filter out sequences that don't have heavy and light chains\n",
    "        for sequence in sequences:\n",
    "            # print(sequence)\n",
    "            species, e_value, score, heavy_chain, light_chain = run_anarci(sequence)\n",
    "            if (len(heavy_chain) > 0) and (len(light_chain) > 0):\n",
    "                sequence_with_heavy_and_light_chains.append(sequence)\n",
    "\n",
    "        return sequence_with_heavy_and_light_chains\n",
    "\n",
    "\n",
    "def percent_identity(seq1, seq2):\n",
    "    \"\"\" Compute the percent identity of two strings of equal length. \"\"\"\n",
    "    if len(seq1) != len(seq2):\n",
    "        raise ValueError('Sequences must be the same length.')\n",
    "    i = 0\n",
    "    for r1, r2 in zip(seq1, seq2):\n",
    "        i += int(r1 == r2)\n",
    "    return i * 100 / len(seq1)\n",
    "\n",
    "def full_seq_identity(df_anarci_H, df_anarci_KL):\n",
    "    df_anarci_H = df_anarci_H.copy().set_index('Id')\n",
    "    df_anarci_KL = df_anarci_KL.copy().set_index('Id')\n",
    "    df_anarci_H['full_seq_H'] = df_anarci_H.loc[:, '1':].apply(lambda x: ''.join(x), axis=1)\n",
    "    df_anarci_KL['full_seq_KL'] = df_anarci_KL.loc[:, '1':].apply(lambda x: ''.join(x), axis=1)\n",
    "    df_anarci = df_anarci_H.merge(df_anarci_KL, left_index=True, right_index=True)\n",
    "    seqs = [x['full_seq_H'] + x['full_seq_KL'] for _, x in df_anarci.iterrows()]\n",
    "\n",
    "    identity_dist = [percent_identity(s[0], s[1]) for s in combinations(seqs, 2)]\n",
    "    return sum(identity_dist) / len(identity_dist)\n",
    "\n",
    "def cdr3_seq_identity(df_anarci_H):\n",
    "    df_seqs = df_anarci_H.loc[:, '105':'117']\n",
    "    seqs = [''.join(x) for _, x in df_seqs.iterrows()]\n",
    "    identity_dist = [percent_identity(s[0], s[1]) for s in combinations(seqs, 2)]\n",
    "    return sum(identity_dist) / len(identity_dist)\n",
    "\n",
    "def diversity_metrics(anarci_csv_path_H, anarci_csv_path_KL):\n",
    "    df_anarci_H = pd.read_csv(anarci_csv_path_H)\n",
    "    df_anarci_KL = pd.read_csv(anarci_csv_path_KL)\n",
    "    results = {'avg_seq_identity_full': full_seq_identity(df_anarci_H, df_anarci_KL),\n",
    "               'avg_seq_identity_cdr3': cdr3_seq_identity(df_anarci_H)}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fda0067-96fa-4cb1-adef-70cc3faf88dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 GPUs!\n",
      "Total Sequences Asked For: 10, Total Sequences Returned: 10, Percent Returned: 1.0\n",
      "Total Sequences Asked For: 10, Total Sequences Returned: 9, Percent Returned: 0.9\n",
      "Total Sequences Asked For: 10, Total Sequences Returned: 8, Percent Returned: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>PD1_avg_seq_identity_cdr3</td><td>▁</td></tr><tr><td>PD1_avg_seq_identity_full</td><td>▁</td></tr><tr><td>PD1_mean_anarci_h_score</td><td>▁</td></tr><tr><td>PD1_mean_anarci_kl_score</td><td>▁</td></tr><tr><td>PD1_min_anarci_h_score</td><td>▁</td></tr><tr><td>PD1_min_anarci_kl_score</td><td>▁</td></tr><tr><td>PD1_number_of_sequences_requested</td><td>▁</td></tr><tr><td>PD1_number_of_sequences_returned</td><td>▁</td></tr><tr><td>PD1_percent_sequences_returned</td><td>▁</td></tr><tr><td>SARS-CoV2_avg_seq_identity_cdr3</td><td>▁</td></tr><tr><td>SARS-CoV2_avg_seq_identity_full</td><td>▁</td></tr><tr><td>SARS-CoV2_mean_anarci_h_score</td><td>▁</td></tr><tr><td>SARS-CoV2_mean_anarci_kl_score</td><td>▁</td></tr><tr><td>SARS-CoV2_min_anarci_h_score</td><td>▁</td></tr><tr><td>SARS-CoV2_min_anarci_kl_score</td><td>▁</td></tr><tr><td>SARS-CoV2_number_of_sequences_requested</td><td>▁</td></tr><tr><td>SARS-CoV2_number_of_sequences_returned</td><td>▁</td></tr><tr><td>SARS-CoV2_percent_sequences_returned</td><td>▁</td></tr><tr><td>mean_of_avg_seq_identity_cdr3</td><td>▁</td></tr><tr><td>mean_of_avg_seq_identity_full</td><td>▁</td></tr><tr><td>total_mean_anarci_h_score</td><td>▁</td></tr><tr><td>total_mean_anarci_kl_score</td><td>▁</td></tr><tr><td>total_min_anarci_h_score</td><td>▁</td></tr><tr><td>total_min_anarci_kl_score</td><td>▁</td></tr><tr><td>total_number_of_sequences_requested</td><td>▁</td></tr><tr><td>total_number_of_sequences_returned</td><td>▁</td></tr><tr><td>total_percent_sequences_returned</td><td>▁</td></tr><tr><td>vWF_avg_seq_identity_cdr3</td><td>▁</td></tr><tr><td>vWF_avg_seq_identity_full</td><td>▁</td></tr><tr><td>vWF_mean_anarci_h_score</td><td>▁</td></tr><tr><td>vWF_mean_anarci_kl_score</td><td>▁</td></tr><tr><td>vWF_min_anarci_h_score</td><td>▁</td></tr><tr><td>vWF_min_anarci_kl_score</td><td>▁</td></tr><tr><td>vWF_number_of_sequences_requested</td><td>▁</td></tr><tr><td>vWF_number_of_sequences_returned</td><td>▁</td></tr><tr><td>vWF_percent_sequences_returned</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>PD1_avg_seq_identity_cdr3</td><td>51.23457</td></tr><tr><td>PD1_avg_seq_identity_full</td><td>84.4164</td></tr><tr><td>PD1_mean_anarci_h_score</td><td>181.64</td></tr><tr><td>PD1_mean_anarci_kl_score</td><td>177.17</td></tr><tr><td>PD1_min_anarci_h_score</td><td>174.9</td></tr><tr><td>PD1_min_anarci_kl_score</td><td>160.6</td></tr><tr><td>PD1_number_of_sequences_requested</td><td>10</td></tr><tr><td>PD1_number_of_sequences_returned</td><td>10</td></tr><tr><td>PD1_percent_sequences_returned</td><td>1.0</td></tr><tr><td>SARS-CoV2_avg_seq_identity_cdr3</td><td>49.53704</td></tr><tr><td>SARS-CoV2_avg_seq_identity_full</td><td>90.38356</td></tr><tr><td>SARS-CoV2_mean_anarci_h_score</td><td>186.42222</td></tr><tr><td>SARS-CoV2_mean_anarci_kl_score</td><td>182.0</td></tr><tr><td>SARS-CoV2_min_anarci_h_score</td><td>178.1</td></tr><tr><td>SARS-CoV2_min_anarci_kl_score</td><td>176.6</td></tr><tr><td>SARS-CoV2_number_of_sequences_requested</td><td>10</td></tr><tr><td>SARS-CoV2_number_of_sequences_returned</td><td>9</td></tr><tr><td>SARS-CoV2_percent_sequences_returned</td><td>0.9</td></tr><tr><td>mean_of_avg_seq_identity_cdr3</td><td>45.3035</td></tr><tr><td>mean_of_avg_seq_identity_full</td><td>86.01776</td></tr><tr><td>total_mean_anarci_h_score</td><td>176.39286</td></tr><tr><td>total_mean_anarci_kl_score</td><td>178.18519</td></tr><tr><td>total_min_anarci_h_score</td><td>99.7</td></tr><tr><td>total_min_anarci_kl_score</td><td>158.5</td></tr><tr><td>total_number_of_sequences_requested</td><td>30</td></tr><tr><td>total_number_of_sequences_returned</td><td>27</td></tr><tr><td>total_percent_sequences_returned</td><td>0.9</td></tr><tr><td>vWF_avg_seq_identity_cdr3</td><td>35.13889</td></tr><tr><td>vWF_avg_seq_identity_full</td><td>83.25333</td></tr><tr><td>vWF_mean_anarci_h_score</td><td>160.53333</td></tr><tr><td>vWF_mean_anarci_kl_score</td><td>175.1625</td></tr><tr><td>vWF_min_anarci_h_score</td><td>99.7</td></tr><tr><td>vWF_min_anarci_kl_score</td><td>158.5</td></tr><tr><td>vWF_number_of_sequences_requested</td><td>10</td></tr><tr><td>vWF_number_of_sequences_returned</td><td>8</td></tr><tr><td>vWF_percent_sequences_returned</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">simple_fine_tuned_progen2-small_prompted</strong> at: <a href='https://wandb.ai/antibody_generation/berkeley_antibody_generation/runs/1y1xfxrn' target=\"_blank\">https://wandb.ai/antibody_generation/berkeley_antibody_generation/runs/1y1xfxrn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231118_203335-1y1xfxrn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 20s, sys: 12.4 s, total: 7min 33s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_path = f'model_checkpoints/{model_name}'\n",
    "device = 'cuda:0'  # Define the device variable outside the if-else condition\n",
    "\n",
    "# Initialize the model first\n",
    "model = ProGenForCausalLM.from_pretrained(model_path).to(device)\n",
    "\n",
    "# Check if multiple GPUs are available and use ProGen's parallelization\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model.parallelize() # ProGen's parallelize method\n",
    "else:\n",
    "    print(f'Device: {device}')\n",
    "\n",
    "tokenizer = Tokenizer.from_file('tokenizer.json')\n",
    "\n",
    "number_of_sequences = 10\n",
    "start_of_antibody_sequence_prompter = 'EVQLVESGGGLVQPGGSLRLSC'\n",
    "\n",
    "targets = [\n",
    "    { \"sequence_id\": 'PD1',\n",
    "      \"sequence\": 'MQIPQAPWPVVWAVLQLGWRPGWFLDSPDRPWNPPTFSPALLVVTEGDNATFTCSFSNTSESFVLNWYRMSPSNQTDKLAAFPEDRSQPGQDCRFRVTQLPNGRDFHMSVVRARRNDSGTYLCGAISLAPKAQIKESLRAELRVTERRAEVPTAHPSPSPRPAGQFQTLVVGVVGGLLGSLVLLVWVLAVICSRAARGTIGARRTGQPLKEDPSAVPVFSVDYGELDFQWREKTPEPPVPCVPEQTEYATIVFPSGMGTSSPARRGSADGPRSAQPLRPEDGHCSWPLGGGGGSGGGGSGGGGS'\n",
    "    },\n",
    "    { \"sequence_id\": 'SARS-CoV2',\n",
    "      \"sequence\": 'RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFGGGGGSGGGGSGGGGS'\n",
    "    },\n",
    "    { \"sequence_id\": 'vWF',\n",
    "      \"sequence\": 'DLVFLLDGSSRLSEAEFEVLKAFVVDMMERLRISQKWVRVAVVEYHDGSHAYIGLKDRKRPSELRRIASQVKYAGSQVASTSEVLKYTLFQIFSKIDRPEASRITLLLMASQEPQRMSRNFVRYVQGLKKKKVIVIPVGIGPHANLKQIRLIEKQAPENKAFVLSSVDELEQQRDEIGGGGGSGGGGSGGGGS'\n",
    "    }\n",
    "]\n",
    "\n",
    "total_number_of_sequences_requested = number_of_sequences * len(targets)\n",
    "total_number_of_sequences_returned = 0\n",
    "total_percent_sequences_returned = 0\n",
    "total_df_result_H = pd.DataFrame()\n",
    "total_df_result_KL = pd.DataFrame()\n",
    "\n",
    "total_avg_seq_identity_full = []\n",
    "total_avg_seq_identity_cdr3 = []\n",
    "\n",
    "for target in targets[:]:\n",
    "\n",
    "    target_sequence_id = target['sequence_id']\n",
    "    target_sequence = target['sequence']\n",
    "    experiment_target_id = f'{experiment_name}_{target_sequence_id}'\n",
    "    \n",
    "    if prompting_strategy == 'prompted':\n",
    "        target_sequence = target_sequence + start_of_antibody_sequence_prompter\n",
    "\n",
    "    sampled_sequences = predict_sequence(model, tokenizer, target_sequence, device, number_of_sequences=number_of_sequences)\n",
    "\n",
    "    df_result_H, df_result_KL = abn.number_seqs_as_df(sampled_sequences)\n",
    "\n",
    "    if (df_result_H is not None) and (len(df_result_H) > 0):\n",
    "        df_result_H['model_id'] = f'{experiment_target_id}_H'\n",
    "        df_result_H.to_csv(f'./results/{experiment_target_id}_H.csv')\n",
    "        mean_anarci_h_score = df_result_H['score'].mean()\n",
    "        min_anarci_h_score = df_result_H['score'].min()\n",
    "        total_df_result_H = pd.concat([total_df_result_H, df_result_H], axis=0)\n",
    "    else:\n",
    "        mean_anarci_h_score = 0\n",
    "        min_anarci_h_score = 0\n",
    "    \n",
    "    if (df_result_KL is not None) and (len(df_result_KL) > 0):\n",
    "        df_result_KL['model_id'] = f'{experiment_target_id}_KL'\n",
    "        df_result_KL.to_csv(f'./results/{experiment_target_id}_KL.csv')\n",
    "        mean_anarci_kl_score = df_result_KL['score'].mean()\n",
    "        min_anarci_kl_score = df_result_KL['score'].min()\n",
    "        total_df_result_KL = pd.concat([total_df_result_KL, df_result_KL], axis=0)\n",
    "    else:\n",
    "        mean_anarci_kl_score = 0\n",
    "        min_anarci_kl_score = 0\n",
    "\n",
    "    if (df_result_H is not None) and (len(df_result_H) > 0) and (df_result_KL is not None) and (len(df_result_KL) > 0):\n",
    "        try:\n",
    "            diversity_metrics_dict = diversity_metrics(f'./results/{experiment_target_id}_H.csv', f'./results/{experiment_target_id}_KL.csv')\n",
    "            avg_seq_identity_full = diversity_metrics_dict['avg_seq_identity_full']\n",
    "            avg_seq_identity_cdr3 = diversity_metrics_dict['avg_seq_identity_cdr3']\n",
    "        except:\n",
    "            avg_seq_identity_full = 0.0\n",
    "            avg_seq_identity_cdr3 = 0.0\n",
    "\n",
    "    else:\n",
    "        avg_seq_identity_full = 0.0\n",
    "        avg_seq_identity_cdr3 = 0.0\n",
    "\n",
    "    number_of_sequences_returned = len(sampled_sequences)\n",
    "    total_number_of_sequences_returned += number_of_sequences_returned    \n",
    "    total_avg_seq_identity_full.append(avg_seq_identity_full)\n",
    "    total_avg_seq_identity_cdr3.append(avg_seq_identity_cdr3)\n",
    "    \n",
    "    wandb.log({\n",
    "        f\"{target_sequence_id}_number_of_sequences_requested\": number_of_sequences, \n",
    "        f\"{target_sequence_id}_number_of_sequences_returned\": number_of_sequences_returned, \n",
    "        f\"{target_sequence_id}_percent_sequences_returned\": number_of_sequences_returned/number_of_sequences,\n",
    "        f\"{target_sequence_id}_mean_anarci_h_score\": mean_anarci_h_score,\n",
    "        f\"{target_sequence_id}_min_anarci_h_score\": min_anarci_h_score,\n",
    "        f\"{target_sequence_id}_mean_anarci_kl_score\": mean_anarci_kl_score,\n",
    "        f\"{target_sequence_id}_min_anarci_kl_score\": min_anarci_kl_score,\n",
    "\n",
    "        f\"{target_sequence_id}_avg_seq_identity_full\": avg_seq_identity_full,\n",
    "        f\"{target_sequence_id}_avg_seq_identity_cdr3\": avg_seq_identity_cdr3,\n",
    "    })\n",
    "\n",
    "    print(f'Total Sequences Asked For: {number_of_sequences}, Total Sequences Returned: {len(sampled_sequences)}, Percent Returned: {len(sampled_sequences)/number_of_sequences}')\n",
    "\n",
    "if len(total_df_result_H) > 0:\n",
    "    total_mean_anarci_h_score = total_df_result_H['score'].mean()\n",
    "    total_min_anarci_h_score = total_df_result_H['score'].min()\n",
    "else:\n",
    "    total_mean_anarci_h_score = 0\n",
    "    total_min_anarci_h_score = 0\n",
    "    \n",
    "if len(total_df_result_KL) > 0:\n",
    "    total_mean_anarci_kl_score = total_df_result_KL['score'].mean()\n",
    "    total_min_anarci_kl_score = total_df_result_KL['score'].min()\n",
    "else:\n",
    "    total_mean_anarci_kl_score = 0\n",
    "    total_min_anarci_kl_score = 0\n",
    "    \n",
    "wandb.log({\n",
    "        f\"total_number_of_sequences_requested\": total_number_of_sequences_requested, \n",
    "        f\"total_number_of_sequences_returned\": total_number_of_sequences_returned, \n",
    "        f\"total_percent_sequences_returned\": total_number_of_sequences_returned/total_number_of_sequences_requested,\n",
    "        f\"total_mean_anarci_h_score\": total_mean_anarci_h_score,\n",
    "        f\"total_min_anarci_h_score\": total_min_anarci_h_score,\n",
    "        f\"total_mean_anarci_kl_score\": total_mean_anarci_kl_score,\n",
    "        f\"total_min_anarci_kl_score\": total_min_anarci_kl_score,\n",
    "        f\"mean_of_avg_seq_identity_full\": np.mean(total_avg_seq_identity_full),\n",
    "        f\"mean_of_avg_seq_identity_cdr3\": np.mean(total_avg_seq_identity_cdr3),\n",
    "    })\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30c3422-57cb-4169-9ae2-85d8e34a6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs.summary.map((row, index) => {Run_name: row.run.name, Train Loss: row[\"avg_train_loss\"], Validation Loss: row[\"avg_val_loss\"], Test Loss: row[\"test_loss\"], Percent Valid Sequences Returned: row[\"total_percent_sequences_returned\"], \"H Chain: Mean ANARCI Score\": row['total_mean_anarci_h_score'], \"KL Chain: Mean ANARCI Score\": row['total_mean_anarci_kl_score']})\n",
    "# runs.summary.map((row, index) => {Run_name: row.run.name, \"Train Loss\": row[\"avg_train_loss\"], \"Validation Loss\": row[\"avg_val_loss\"], \"Test Loss\": row[\"test_loss\"], \"Percent Valid Sequences Returned\": row[\"total_percent_sequences_returned\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f8e0a1-e5c0-4851-8a3c-6d587e9976f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs.summary.map((row, index) => {Run_name: row.run.name, Train_Loss: row[\"avg_train_loss\"], Validation_Loss: row[\"avg_val_loss\"], Test_Loss: row[\"test_loss\"], Percent_Valid_Sequences_Returned: row[\"total_percent_sequences_returned\"], HChain_Mean_ANARCI_Score: row['total_mean_anarci_h_score'], KLChain_Mean_ANARCI_Score: row['total_mean_anarci_kl_score']})"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "anarci",
   "language": "python",
   "name": "anarci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
